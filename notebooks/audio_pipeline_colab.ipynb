{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helitb/iris-poc/blob/main/notebooks/audio_pipeline_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e539a2a",
      "metadata": {
        "id": "2e539a2a"
      },
      "source": [
        "# IRIS Audio Pipeline (Colab GPU)\n",
        "\n",
        "Notebook to exercise the audio pipeline on a Colab GPU runtime. It installs GPU-ready deps, loads the IRIS code, and runs a sample window over a WAV file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7248302a",
      "metadata": {
        "id": "7248302a"
      },
      "source": [
        "## Prep\n",
        "- Runtime ➜ Change runtime type ➜ GPU\n",
        "- Place this repo at `/content/IRIS` (clone or upload). The pipeline code lives in `poc/src` and sample audio in `poc/data/audio`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_SX9wXkMIyTu"
      },
      "id": "_SX9wXkMIyTu"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bb6e2569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6e2569",
        "outputId": "4e308380-c1af-45a7-8c42-f679a5df5773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 28 17:07:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "torch 2.9.0+cu126\n",
            "cuda available True\n"
          ]
        }
      ],
      "source": [
        "# Check GPU is visible\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print('torch', torch.__version__)\n",
        "print('cuda available', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481be6c4",
      "metadata": {
        "id": "481be6c4"
      },
      "source": [
        "Install dependencies (CUDA wheel picked automatically from nvidia-smi)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9019a77b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9019a77b",
        "outputId": "0abbd7a4-adef-40c2-d11e-78d741fa0080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA wheels: cu121\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "CUDA_VARIANT = 'cu121'  # fallback\n",
        "try:\n",
        "    smi = subprocess.check_output(['nvidia-smi']).decode()\n",
        "    if 'CUDA Version: 11.' in smi:\n",
        "        CUDA_VARIANT = 'cu118'\n",
        "    elif 'CUDA Version: 12.' in smi:\n",
        "        CUDA_VARIANT = 'cu121'\n",
        "except Exception as exc:  # noqa: BLE001\n",
        "    print('Could not auto-detect CUDA version, defaulting to cu121:', exc)\n",
        "\n",
        "print(f'Using CUDA wheels: {CUDA_VARIANT}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q --extra-index-url https://download.pytorch.org/whl/$CUDA_VARIANT torch>=2.0.0 torchaudio>=2.0.0\n",
        "!pip install -q -f https://opennmt.net/CTranslate2/whl/$CUDA_VARIANT ctranslate2==4.3.1 faster-whisper==1.0.3\n",
        "!pip install -q silero-vad speechbrain praat-parselmouth sentence-transformers soundfile"
      ],
      "metadata": {
        "id": "RoMbVl-GAdhM"
      },
      "id": "RoMbVl-GAdhM",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9ffc9e5b",
      "metadata": {
        "id": "9ffc9e5b"
      },
      "source": [
        "**Get the code**\n",
        "- If the repo is public, set `REPO_URL` to clone.\n",
        "- Otherwise upload/drag the `IRIS` folder into the Colab file pane or mount Drive to `/content/IRIS`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_TOKEN = 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIJ8TmVot0mr67ykcBMd1bWmHxSjWl9z6I/RoO/IOiTHl'\n",
        "token_len = len(GITHUB_TOKEN)\n",
        "print(f\"git token size is {token_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axg4L9uI_qIX",
        "outputId": "4b96d280-5a56-4d02-fd72-f5702d06533b"
      },
      "id": "axg4L9uI_qIX",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git token size is 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9b4572c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b4572c5",
        "outputId": "18d1efea-bfde-4710-f297-18c5bb870a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AAAAC3NzaC1lZDI1NTE5AAAAIJ8TmVot0mr67ykcBMd1bWmHxSjWl9z6I/RoO/IOiTHl@github.com//iris-poc.git'...\n",
            "fatal: unable to access 'https://-ed25519/': Could not resolve host: -ed25519\n"
          ]
        }
      ],
      "source": [
        "GITHUB_TOKEN = 'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIJ8TmVot0mr67ykcBMd1bWmHxSjWl9z6I/RoO/IOiTHl'\n",
        "\n",
        "REPO_URL = 'helitb/iris-poc.git'\n",
        "if REPO_URL:\n",
        "    !rm -rf /content/iris-poc\n",
        "    !git clone https://${GITHUB_TOKEN}@github.com/${REPO_URL}\n",
        "else:\n",
        "    print('Upload or mount the IRIS repo to /content/IRIS (with poc/src and poc/data/audio).')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_URL = 'helitb/iris-poc.git'\n",
        "if REPO_URL:\n",
        "    !rm -rf /content/iris-poc\n",
        "    !git clone https://github.com/helitb/iris-poc\n",
        "else:\n",
        "    print('Upload or mount the IRIS repo to /content/IRIS (with poc/src and poc/data/audio).')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JgcfNhRGIJF",
        "outputId": "6cea08bd-7a96-4c53-9a42-8f9d5a89770f"
      },
      "id": "8JgcfNhRGIJF",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iris-poc'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 29 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (29/29), 6.41 MiB | 23.62 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "PROJECT_ROOT = Path('/content/iris-poc')\n",
        "CODE_ROOT = PROJECT_ROOT / 'src' / 'audio'\n",
        "if not CODE_ROOT.exists():\n",
        "    raise FileNotFoundError('IRIS code not found. Ensure /content/iris-poc/poc/src exists (see previous cell).')\n",
        "\n",
        "sys.path.append(str(CODE_ROOT))\n",
        "print('Using code from', CODE_ROOT)"
      ],
      "metadata": {
        "id": "55aV8cRJ8ETD",
        "outputId": "66ffacdb-3b5c-4186-9f2e-46766999e90b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "55aV8cRJ8ETD",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using code from /content/iris-poc/src/audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "877363c0",
      "metadata": {
        "id": "877363c0"
      },
      "source": [
        "## Audio Pipeline\n",
        "\n",
        "Load a sample WAV (replace with your own if you want)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5556c862",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5556c862",
        "outputId": "76833ced-4711-4def-c83d-2d910a1b96bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded slice2_audio.wav: sr=16000, shape=(480011,), duration=30.00s\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "AUDIO_FILE = PROJECT_ROOT / 'data' / 'audio' / 'slice2_audio.wav'\n",
        "if not AUDIO_FILE.exists():\n",
        "    raise FileNotFoundError('Audio file not found. Point AUDIO_FILE to a WAV you uploaded.')\n",
        "\n",
        "audio, sr = sf.read(AUDIO_FILE, dtype='float32')\n",
        "if audio.ndim > 1:\n",
        "    audio = audio.mean(axis=1)  # mono\n",
        "\n",
        "TARGET_SR = 16000\n",
        "if sr != TARGET_SR:\n",
        "    import librosa\n",
        "    audio = librosa.resample(audio, orig_sr=sr, target_sr=TARGET_SR)\n",
        "    sr = TARGET_SR\n",
        "\n",
        "print(f'Loaded {AUDIO_FILE.name}: sr={sr}, shape={audio.shape}, duration={len(audio)/sr:.2f}s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e518c6c",
      "metadata": {
        "id": "2e518c6c"
      },
      "source": [
        "Run the pipeline over the window. Switch `diarization_backend` to `'simple'` if you want a faster lightweight diarizer. Set `enable_prosody=True` to test prosody (adds compute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fcce10f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "fcce10f3",
        "outputId": "eaa1fadf-9790-4af3-a7f2-2ac8df6210ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torchaudio' has no attribute 'list_audio_backends'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1022183211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m config = PipelineConfig(\n\u001b[1;32m      5\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/iris-poc/src/audio/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSileroVAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_vad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeakerDiarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_diarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUtteranceSegmenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTurnTakingAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_segmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0masr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHebrewASR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_asr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/iris-poc/src/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m from .pipeline import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mAudioPipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mRollingBufferPipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/iris-poc/src/audio/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSileroVAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_vad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeakerDiarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_diarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUtteranceSegmenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTurnTakingAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_segmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0masr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHebrewASR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_asr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/iris-poc/src/audio/diarization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpeechSegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiarizedSegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_experiment_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated_redirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_export_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeechbrain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoopedLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveableDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m from speechbrain.dataio.sampler import (\n\u001b[1;32m     41\u001b[0m     \u001b[0mDistributedSamplerWrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/dataio/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchsizeGuesser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPaddedBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDynamicItemDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m from speechbrain.dataio.sampler import (\n\u001b[1;32m     48\u001b[0m     \u001b[0mDistributedSamplerWrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/dataio/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_data_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/dataio/dataio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mcheck_torchaudio_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/speechbrain/utils/torch_audio_backend.py\u001b[0m in \u001b[0;36mcheck_torchaudio_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtorchaudio_major\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorchaudio_minor\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mavailable_backends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_audio_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable_backends\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchaudio' has no attribute 'list_audio_backends'"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from pipeline import AudioPipeline, PipelineConfig\n",
        "\n",
        "config = PipelineConfig(\n",
        "    debug=True,\n",
        "    diarization_backend='simple',  # use 'simple' for fastest smoke test\n",
        "    asr_model='ivrit-v2-d4',            # Hebrew optimized faster-whisper\n",
        "    enable_prosody=False,               # enable to exercise prosody extractor\n",
        "    retain_transcripts=True,\n",
        ")\n",
        "\n",
        "pipeline = AudioPipeline(config)\n",
        "result = pipeline.process_window(audio, datetime.now())\n",
        "\n",
        "print(f'Processing time: {result.processing_time_ms} ms')\n",
        "print(f'Utterances: {result.num_utterances}, Speakers detected: {result.speakers_detected}')\n",
        "print('--- Sample events ---')\n",
        "for evt in result.speech_events[:5]:\n",
        "    print(evt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "249656ce",
      "metadata": {
        "id": "249656ce"
      },
      "source": [
        "Optional: tabular view of events (keeps transcripts only because retain_transcripts=True above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e8540ea",
      "metadata": {
        "id": "7e8540ea"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for evt in result.speech_events:\n",
        "    rows.append({\n",
        "        'timestamp': evt.timestamp,\n",
        "        'speaker': getattr(evt.speaker, 'id', None),\n",
        "        'duration_ms': evt.duration_ms,\n",
        "        'text': getattr(evt, 'transcription', None),\n",
        "        'complexity': getattr(evt, 'complexity', None),\n",
        "        'gap_before_ms': evt.gap_before_ms,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}